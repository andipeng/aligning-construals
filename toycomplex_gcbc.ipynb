{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0f04c0-b995-48ad-b9db-00745cd52376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andipeng/miniforge3/envs/aligning-construals/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "GCBC with point maze (with multi-goal + color state space)\n",
    "'''\n",
    "from __future__ import print_function, division, unicode_literals\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import distributions as pyd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode - o\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec198b80-0ffe-4340-8215-9eb257929cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim, hidden_dim, output_dim, hidden_depth, output_mod=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.trunk = mlp(input_dim, hidden_dim, output_dim, hidden_depth, output_mod)\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.trunk(x)\n",
    "    \n",
    "def mlp(input_dim, hidden_dim, output_dim, hidden_depth, output_mod=None):\n",
    "    if hidden_depth == 0:\n",
    "        mods = [nn.Linear(input_dim, output_dim)]\n",
    "    else:\n",
    "        mods = [nn.Linear(input_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        for i in range(hidden_depth - 1):\n",
    "            mods += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU(inplace=True)]\n",
    "        mods.append(nn.Linear(hidden_dim, output_dim))\n",
    "    if output_mod is not None:\n",
    "        mods.append(output_mod)\n",
    "    trunk = nn.Sequential(*mods)\n",
    "    return trunk\n",
    "\n",
    "# Custom weight init for Conv2D and Linear layers\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.orthogonal_(m.weight.data)\n",
    "        if hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ba699-052b-4963-bc27-366082dc1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal-conditioned Point Maze (with multi state + color)\n",
    "# self.color = [red, green, blue, orange] (one hot encoded)\n",
    "import gym\n",
    "import gym.wrappers\n",
    "\n",
    "class PointEnvComplex(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.pos = np.array([0., 0.])\n",
    "        self.obj1 = np.array([-1., -1.])\n",
    "        self.color1 = np.array([0., 0., 0., 0.])\n",
    "        self.obj2 = np.array([-1., -1.])\n",
    "        self.color2 = np.array([0., 0., 0., 0.])\n",
    "        self.obj3 = np.array([-1., -1.])\n",
    "        self.color3 = np.array([0., 0., 0., 0.])\n",
    "        self.goal = np.array([0., 0., 0., 0.])\n",
    "        self.max_vel = 1\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            -np.inf * np.ones(24), np.inf * np.ones(24)\n",
    "        )\n",
    "        self.action_space = gym.spaces.Box(-np.ones(2), np.ones(2))\n",
    "        self.action_space.seed(0)\n",
    "        self.observation_space.seed(0)\n",
    "\n",
    "    def reset(self):\n",
    "        self.pos = np.zeros((2,))\n",
    "        self.obj1 = np.zeros((2,))\n",
    "        self.color1 = np.zeros((4,))\n",
    "        self.obj2 = np.zeros((2,))\n",
    "        self.color2 = np.zeros((4,))\n",
    "        self.obj3 = np.zeros((2,))\n",
    "        self.color3 = np.zeros((4,))\n",
    "        self.goal = np.ones((4,))\n",
    "        return self.get_obs()\n",
    "\n",
    "    def get_obs(self):\n",
    "        return copy.deepcopy(np.concatenate([self.pos, self.obj1, self.color1, self.obj2, self.color2, self.obj3, self.color3, self.goal]))\n",
    "\n",
    "    def step(self, action: np.ndarray):\n",
    "        self.pos += self.max_vel*action\n",
    "        reward = -np.linalg.norm((self.pos - self.goal))\n",
    "        return self.get_obs(), reward, False, {}\n",
    "    \n",
    "    def reward_fn(self, state):\n",
    "        return -torch.linalg.norm((state - torch.Tensor(self.goal).to(device)), dim=-1)\n",
    "    \n",
    "env1 = PointEnvComplex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c84ebf-c829-48f6-975f-3c4923c63962",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(-10, 10)\n",
    "plt.ylim(-10, 10)\n",
    "colors = sns.color_palette(\"hls\", 10)\n",
    "\n",
    "# Collect random rollouts from the environment, store it in some datasets\n",
    "num_trajs = 100\n",
    "train_trajs = []\n",
    "angles = []\n",
    "\n",
    "for tn in range(num_trajs):\n",
    "    o = env1.reset().copy()\n",
    "    #end_pos = np.random.uniform(-5, 5, size=(2,)) # Random ending point\n",
    "    angle = np.random.uniform(0, 2*np.pi) # samples angle in radians\n",
    "    end_pos = np.array([5*np.cos(angle), 5*np.sin(angle)])\n",
    "    env1.goal = end_pos\n",
    "    delta_vector = end_pos# - env1.pos # calculates distance to goal pos\n",
    "    o = env1.get_obs()\n",
    "    traj = {'obs': [],'action': [], 'next_obs': []}\n",
    "    for i in range(100):\n",
    "        ac = delta_vector * 0.01 # Go in direction between start and end\n",
    "        no, r, d, _ = env1.step(ac)\n",
    "        traj['obs'].append(o.copy())\n",
    "        traj['action'].append(ac.copy())\n",
    "        traj['next_obs'].append(no.copy())\n",
    "        o = no.copy()\n",
    "    traj['obs'] = np.array(traj['obs'])\n",
    "    traj['action'] = np.array(traj['action'])\n",
    "    traj['next_obs'] = np.array(traj['next_obs'])\n",
    "    plt.plot(traj['obs'][:, 0], traj['obs'][:, 1]) # plots trajs + goals\n",
    "    plt.scatter([end_pos[0]],[end_pos[1]], marker='x', s=20)\n",
    "    train_trajs.append(traj)\n",
    "    angle_curr = np.arctan2(traj['obs'][-1, 0], traj['obs'][-1, 1])\n",
    "    angles.append(angle_curr.copy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aligning-construals] *",
   "language": "python",
   "name": "conda-env-aligning-construals-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
